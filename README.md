# Fiction Generation Pipeline

A professional-grade AI-powered fiction writing system using LangChain and OpenRouter. This implements a hierarchical agent-based workflow with quality gates, lore management, and editorial review to generate complete novels from concept to polished manuscript.

## ğŸ¯ Features

### Core Architecture
- **Agent-Based Pipeline**: Specialized AI agents for each stage of fiction creation
- **Quality Gates**: QA Agent + Lore Master validate every stage before progression
- **Lore Management**: Pinecone vector database tracks and enforces world-building consistency
- **Editorial Pipeline**: Professional editing workflow (Story Analysis â†’ Consistency â†’ Developmental â†’ Line Editing)
- **State Persistence**: Checkpoint and resume capability at any stage
- **Structured Data**: Complete Pydantic schemas ensure type safety and validation

### Workflow Stages

```
Series Concept
    â†“
[Series Refiner] â†’ Creates series outline, initial lore
    â†“ [QA + Lore Master validation]
[Book Outliner] â†’ 3-act structure, character arcs, chapter scaffold
    â†“ [QA + Lore Master validation]
[Chapter Developer] â†’ Detailed chapter breakdowns with scenes
    â†“ [QA + Lore Master validation]
[Scene Developer] â†’ Scene-level detail (POV, conflicts, turning points)
    â†“ [QA + Lore Master validation]
[Beat Developer] â†’ Story beats (action, dialogue, description units)
    â†“ [QA + Lore Master validation]
[Prose Generator] â†’ Actual narrative prose from beats
    â†“ [QA + Lore Master validation]
[Editorial Phase] â†’ Story Analyst â†’ Consistency Validator â†’ Dev Editor â†’ Line Editor
    â†“ [Final QA]
[Export] â†’ manuscript.md + complete project.json
```

## ğŸ“ Project Structure

```
fiction-pipeline/
â”œâ”€â”€ agents/                     # AI agents for each workflow stage
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_agent.py          # Abstract base class
â”‚   â”œâ”€â”€ series_refiner.py      # Series outline creation
â”‚   â”œâ”€â”€ book_outliner.py       # Book structure development
â”‚   â”œâ”€â”€ chapter_developer.py   # Chapter breakdown
â”‚   â”œâ”€â”€ scene_developer.py     # Scene development
â”‚   â”œâ”€â”€ beat_developer.py      # Beat creation
â”‚   â”œâ”€â”€ prose_generator.py     # Prose writing
â”‚   â”œâ”€â”€ qa_agent.py            # Quality assurance
â”‚   â”œâ”€â”€ lore_master.py         # Lore consistency checking
â”‚   â”œâ”€â”€ story_analyst.py       # Developmental story analysis
â”‚   â”œâ”€â”€ consistency_validator.py  # Continuity validation
â”‚   â”œâ”€â”€ developmental_editor.py   # Structural editing
â”‚   â””â”€â”€ line_editor.py         # Prose polishing
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ schema.py              # Pydantic data models
â”œâ”€â”€ validators/
â”‚   â””â”€â”€ schema_validator.py    # Schema validation
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ logger.py              # Logging utilities
â”‚   â”œâ”€â”€ state_manager.py       # Checkpoint management
â”‚   â”œâ”€â”€ prompts.py             # Versioned prompt templates
â”‚   â””â”€â”€ lore_store.py          # Pinecone vector store wrapper
â”œâ”€â”€ tests/                     # Unit and integration tests
â”œâ”€â”€ output/                    # Generated JSON checkpoints
â”œâ”€â”€ logs/                      # Execution logs
â”œâ”€â”€ pipeline.py                # Main orchestrator
â”œâ”€â”€ run.py                     # CLI entry point
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ Installation

### Prerequisites
- Python 3.10+
- OpenRouter API key ([Get one here](https://openrouter.ai/keys))
- Pinecone API key (optional, for lore management) ([Get one here](https://www.pinecone.io/))

### Setup

```bash
# Clone or download the project
cd fiction-pipeline

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
# Create .env file:
echo "OPENROUTER_API_KEY=your-key-here" > .env
echo "PINECONE_API_KEY=your-key-here" >> .env  # Optional
```

## ğŸ“ Usage

### Quick Start

```python
from pipeline import FictionPipeline
from models.schema import FictionProject, Metadata, Series, Lore
from datetime import datetime

# Create initial project
project = FictionProject(
    metadata=Metadata(
        last_updated=datetime.now(),
        last_updated_by="User",
        processing_stage="series",
        status="draft",
        project_id="my_novel_001",
        iteration=1
    ),
    series=Series(
        title="The Quantum Heist",
        premise="A team of specialists must steal an impossible artifact from a time-locked vault.",
        genre="science fiction",
        target_audience="adult",
        themes=[],
        persistent_threads=[],
        lore=Lore(),
        books=[]
    )
)

# Initialize pipeline
pipeline = FictionPipeline(
    project_id="my_novel_001",
    output_dir="output"
)

# Run complete pipeline
final_project = pipeline.run(project)

# Export manuscript
pipeline.export_manuscript(final_project, "manuscripts/")
```

### CLI Usage

```bash
# Run full pipeline from series concept
python run.py --input series_concept.txt --project-id my-novel --output output/

# Resume from checkpoint
python run.py --project-id my-novel --resume

# Run specific stage only
python run.py --project-id my-novel --stage book_outliner

# Run with editorial phase
python run.py --project-id my-novel --run-editorial
```

### Input Format (series_concept.txt)

```
The Quantum Heist
A team of specialists must steal an impossible artifact from a time-locked vault.
science fiction
```

## ğŸ¨ Model Configuration (**âœ… FULLY CUSTOMIZABLE!**)

### Per-Agent Model Customization

Each agent in the pipeline can use a different model and parameters. Configure via **presets** or **custom configuration**.

### Quick Start: Using Presets

```python
from pipeline import FictionPipeline

# Option 1: Balanced (default) - Good quality, reasonable cost
pipeline = FictionPipeline(
    project_id="my-novel",
    preset="balanced"
)

# Option 2: Creative - Maximum creativity/temperature
pipeline = FictionPipeline(
    project_id="my-novel",
    preset="creative"
)

# Option 3: Precise - Maximum consistency, low temperature
pipeline = FictionPipeline(
    project_id="my-novel",
    preset="precise"
)

# Option 4: Cost Optimized - Uses Claude Haiku for most stages
pipeline = FictionPipeline(
    project_id="my-novel",
    preset="cost_optimized"
)

# Option 5: Premium - Claude Opus for everything (best quality, highest cost)
pipeline = FictionPipeline(
    project_id="my-novel",
    preset="premium"
)
```

### Custom Configuration Per Agent

```python
custom_config = {
    "prose": {
        "model": "anthropic/claude-3-opus",  # Best model for prose
        "temperature": 0.95,                 # Maximum creativity
        "max_tokens": 3000
    },
    "qa": {
        "model": "openai/gpt-4",            # Different provider for QA
        "temperature": 0.4
    },
    "series": {
        "temperature": 0.2                   # Very structured planning
    }
    # Other agents use defaults
}

pipeline = FictionPipeline(
    project_id="my-novel",
    model_config=custom_config
)
```

### Available Configuration Options

Each agent supports:

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `model` | str | `anthropic/claude-3.5-sonnet` | Model identifier |
| `temperature` | float | varies | 0.0-1.0 (lower=consistent, higher=creative) |
| `max_tokens` | int | varies | Maximum response length |
| `top_p` | float | None | Nucleus sampling (0.0-1.0) |
| `frequency_penalty` | float | None | Reduce repetition (-2.0 to 2.0) |
| `presence_penalty` | float | None | Encourage topic diversity (-2.0 to 2.0) |

### Default Temperatures by Agent

| Agent | Default Temp | Rationale |
|-------|--------------|-----------|
| `series` | 0.3 | Structured series planning |
| `book` | 0.3 | Logical act structure |
| `chapter` | 0.4 | Balanced scene planning |
| `scene` | 0.5 | Moderate beat creativity |
| `beat` | 0.3 | Structured beat planning |
| `prose` | **0.8** | **HIGH for creative prose** âœ¨ |
| `qa` | 0.5 | Balanced critical analysis |
| `lore` | 0.4 | Consistent lore validation |

### Preset Details

**`balanced`** (default)
- Claude 3.5 Sonnet for all agents
- Temperature: 0.3-0.8 (structured â†’ creative)
- Best for: General use, good quality at reasonable cost

**`creative`**
- Claude 3.5 Sonnet for all agents
- Temperature: 0.5-0.95 (moderate â†’ maximum creativity)
- Best for: Experimental fiction, literary prose, unique styles

**`precise`**
- Claude 3.5 Sonnet for all agents
- Temperature: 0.2-0.5 (very structured)
- Best for: Series with complex lore, technical accuracy needed

**`cost_optimized`**
- Claude Haiku for structure (series, book, chapter, scene, beat, qa, lore)
- Claude 3.5 Sonnet for prose only
- Best for: Budget-conscious projects, first drafts

**`premium`**
- Claude Opus for nearly everything
- Claude 3.5 Sonnet for beat stage only
- Temperature: Higher overall for quality + creativity
- Best for: Final polished manuscripts, maximum quality

### Available Models on OpenRouter

```python
# Anthropic (Best for creative writing)
"anthropic/claude-3.5-sonnet"  # Balanced, recommended
"anthropic/claude-3-opus"      # Best quality, highest cost
"anthropic/claude-3-haiku"     # Fast and cheap

# OpenAI
"openai/gpt-4-turbo"
"openai/gpt-4o"
"openai/gpt-4o-mini"

# Google
"google/gemini-pro-1.5"
"google/gemini-flash-1.5"

# Meta
"meta-llama/llama-3.1-405b-instruct"
"meta-llama/llama-3.1-70b-instruct"

# See full list: https://openrouter.ai/models
```

### Example: Mix and Match Providers

```python
# Use Claude for prose, GPT-4 for QA, Gemini for structure
config = {
    "series": {"model": "google/gemini-pro-1.5", "temperature": 0.3},
    "book": {"model": "google/gemini-pro-1.5", "temperature": 0.3},
    "prose": {"model": "anthropic/claude-3-opus", "temperature": 0.9},
    "qa": {"model": "openai/gpt-4", "temperature": 0.4}
}

pipeline = FictionPipeline(project_id="test", model_config=config)
```

### Configuration at Runtime

When you initialize the pipeline, it prints the active configuration:

```
ğŸ¤– Model Configuration:
  series       â†’ anthropic/claude-3.5-sonnet              (temp=0.3)
  book         â†’ anthropic/claude-3.5-sonnet              (temp=0.3)
  chapter      â†’ anthropic/claude-3.5-sonnet              (temp=0.4)
  scene        â†’ anthropic/claude-3.5-sonnet              (temp=0.5)
  beat         â†’ anthropic/claude-3.5-sonnet              (temp=0.3)
  prose        â†’ anthropic/claude-3-opus                  (temp=0.9)
  qa           â†’ openai/gpt-4                             (temp=0.4)
  lore         â†’ anthropic/claude-3.5-sonnet              (temp=0.4)
```

See `example_custom_models.py` for complete working examples.

## ğŸ—‚ï¸ Data Schema

### Complete Hierarchy

```
FictionProject
â”œâ”€â”€ metadata (version, status, stage)
â”œâ”€â”€ series
â”‚   â”œâ”€â”€ title, premise, themes, genre
â”‚   â”œâ”€â”€ lore
â”‚   â”‚   â”œâ”€â”€ characters (name, role, traits, relationships)
â”‚   â”‚   â”œâ”€â”€ locations (name, description, significance)
â”‚   â”‚   â””â”€â”€ world_elements (name, type, rules)
â”‚   â””â”€â”€ books[]
â”‚       â”œâ”€â”€ title, premise, themes
â”‚       â”œâ”€â”€ act_structure (3 acts with key events)
â”‚       â”œâ”€â”€ character_arcs[]
â”‚       â””â”€â”€ chapters[]
â”‚           â”œâ”€â”€ title, purpose, act
â”‚           â”œâ”€â”€ character_focus (POV, present, arc moments)
â”‚           â””â”€â”€ scenes[]
â”‚               â”œâ”€â”€ purpose, scene_type, POV, setting
â”‚               â”œâ”€â”€ conflicts[], turning_points[]
â”‚               â””â”€â”€ beats[]
â”‚                   â”œâ”€â”€ description, emotional_tone
â”‚                   â””â”€â”€ prose (content, word_count)
â”œâ”€â”€ qa_reports[] (quality assurance feedback)
â”œâ”€â”€ editorial_reports[] (story analysis, consistency, edits)
â””â”€â”€ revision_history[] (change tracking)
```

## ğŸ” Quality Gates

Every stage includes validation:

1. **Schema Validation**: Pydantic ensures data structure integrity
2. **QA Agent Review**: Checks structure, pacing, character arcs, themes
3. **Lore Master Validation**: Enforces consistency with established lore
4. **Retry Logic**: Automatically retries with feedback (max 3 attempts)

### Approval Flow

```
[Agent Generates Content]
    â†“
[Schema Validator] â†’ PASS/FAIL
    â†“ PASS
[QA Agent] â†’ Scores + Approval
    â†“ APPROVED?
    â”œâ”€ NO â†’ Inject feedback, retry (max 3x)
    â””â”€ YES â†’ Continue
        â†“
[Lore Master] â†’ Lore Validation
    â†“ APPROVED?
    â”œâ”€ NO â†’ Inject feedback, retry (max 3x)
    â””â”€ YES â†’ Advance to next stage
```

## ğŸ­ Lore Management (**âœ… IMPLEMENTED!**)

### Automatic Lore Database with Pinecone

The system automatically stores and queries lore using a vector database for consistency:

**Setup (Optional but Recommended):**

1. **Get Pinecone API Key**: Sign up at [pinecone.io](https://www.pinecone.io/)
2. **Set Environment Variable**:
   ```bash
   # Windows
   set PINECONE_API_KEY=your-pinecone-key

   # Linux/Mac
   export PINECONE_API_KEY=your-pinecone-key
   ```
3. **Enable in Pipeline**:
   ```python
   pipeline = FictionPipeline(
       project_id="my-novel",
       use_lore_db=True  # Default: True
   )
   ```

**What Happens Automatically:**

1. **After Series Refiner** â†’ All lore (characters, locations, world elements) stored in Pinecone
2. **Before Each Generation** â†’ Agents query relevant lore (semantic search, top 10 matches)
3. **During Quality Gates** â†’ Lore Master checks for contradictions
4. **Lore Gets Injected** â†’ Relevant lore added to prompts automatically

**If Pinecone Not Available:**
- System falls back to JSON-only lore storage
- Prints warning: `âš ï¸ Warning: PINECONE_API_KEY not set. Lore vector store disabled.`
- Everything still works, just without semantic lore retrieval

### Lore Workflow

```
[Series Refiner] â†’ Creates initial lore entries
    â†“
[Store in Pinecone] âœ… AUTOMATIC â†’ Vector embeddings
    â†“
[Each Agent] âœ… AUTOMATIC â†’ Queries relevant lore (top 10) via semantic search
    â†“ (Lore injected into prompts)
[Generate Content] â†’ Uses relevant lore context
    â†“
[Lore Master] â†’ Quality Gate:
    â”œâ”€ Detects lore breaks â†’ FAIL, retry with feedback
    â””â”€ Detects new lore â†’ Logged in qa_reports
```

### Example Lore Query

When generating Chapter 3, the system automatically:
```python
# Behind the scenes:
lore = lore_store.query_lore(
    query="Chapter 3: The protagonist confronts the antagonist",
    project_id="my-novel",
    top_k=10
)
# Returns: protagonist details, antagonist info, relevant locations, rules
# â†’ Injected into prompt to ensure consistency
```

## âœï¸ Editorial Pipeline

Professional editing workflow after prose generation:

### Phase 1: Developmental Editing

```
[Story Analyst] â†’ Compare prose vs. original outline
    â†“ Identifies:
    â”œâ”€ Plot holes
    â”œâ”€ Character arc breaks
    â”œâ”€ Pacing issues
    â””â”€ Theme drift
    â†“
[Consistency Validator] â†’ Check lore/continuity
    â†“ Identifies:
    â”œâ”€ Lore violations
    â”œâ”€ Timeline conflicts
    â””â”€ Logic gaps
    â†“
[Developmental Editor] â†’ Fix major issues
    â†“ (Re-analyze until approved)
```

### Phase 2: Line Editing

```
[Line Editor] â†’ Sentence-level polish
    â†“ Improves:
    â”œâ”€ Tighten prose (remove fluff)
    â”œâ”€ Fix awkward sentences
    â”œâ”€ Enhance descriptions
    â””â”€ Polish voice consistency
    â†“
[Final QA] â†’ Approval gate
    â†“ APPROVED?
    â””â”€ YES â†’ Export manuscript
```

## ğŸ’° Cost Estimation

Using **Claude 3.5 Sonnet** on OpenRouter:

| Stage | API Calls | Est. Cost |
|-------|-----------|-----------|
| Series Refiner | 1 | $0.10 |
| Book Outliner | 1 per book | $0.20 |
| Chapter Developer | ~20 | $2.00 |
| Scene Developer | ~60 | $4.00 |
| Beat Developer | ~200 | $6.00 |
| Prose Generator | ~200 | $15.00 |
| QA + Lore (all stages) | ~40 | $3.00 |
| Editorial Phase | ~50 | $5.00 |
| **Total (1 book, ~100k words)** | **~600** | **~$35** |

### Cost-Saving Tips

1. **Use `cost_optimized` preset**: Automatically uses Claude Haiku for structure stages
   ```python
   pipeline = FictionPipeline(project_id="my-novel", preset="cost_optimized")
   ```
   Estimated savings: ~70% reduction ($35 â†’ ~$10 per book)

2. **Generate fewer chapters first**: Test with 5 chapters before full book

3. **Skip editorial**: Go straight from prose to export

4. **Use model mixing**: Cheap models for structure, good model for prose only
   ```python
   config = {
       "series": {"model": "anthropic/claude-3-haiku"},
       "book": {"model": "anthropic/claude-3-haiku"},
       "chapter": {"model": "anthropic/claude-3-haiku"},
       "scene": {"model": "anthropic/claude-3-haiku"},
       "prose": {"model": "anthropic/claude-3.5-sonnet", "temperature": 0.8}
   }
   ```

## ğŸ§ª Testing

```bash
# Run unit tests
pytest tests/test_schema.py

# Run integration tests
pytest tests/test_pipeline.py

# Test with minimal fixture
python run.py --input tests/fixtures/minimal_series.txt --project-id test-001
```

## ğŸ”§ Advanced Configuration

### Environment Variables

```bash
# Required
OPENROUTER_API_KEY=sk-or-v1-...

# Optional
PINECONE_API_KEY=...  # For lore vector database
```

### Pipeline Initialization Options

```python
pipeline = FictionPipeline(
    project_id="my-novel",           # Unique identifier
    output_dir="output",             # Checkpoint directory
    openrouter_api_key="sk-or-...",  # Or use env var
    use_lore_db=True,                # Enable Pinecone (default: True)
    preset="balanced",               # Preset configuration
    model_config=None                # Custom per-agent config
)
```

### Reproducibility

For deterministic outputs (useful for testing), use low temperatures:

```python
pipeline = FictionPipeline(
    project_id="test",
    preset="precise"  # All temperatures 0.2-0.5
)
```

Note: True determinism requires model provider support (some models don't support seed parameters).

## ğŸ“Š Output

### Generated Files

```
output/
â”œâ”€â”€ my-novel_state.json         # Complete project data
â”œâ”€â”€ my-novel_v1.json            # Checkpoint after stage 1
â”œâ”€â”€ my-novel_v2.json            # Checkpoint after stage 2
â””â”€â”€ ...

manuscripts/
â”œâ”€â”€ my-novel_manuscript.md      # Final prose (Markdown format)
â””â”€â”€ my-novel_final.json         # Complete project with all metadata
```

### Manuscript Format

```markdown
# The Quantum Heist
*A team of specialists must steal an impossible artifact from a time-locked vault.*

---

# Book 1: The Impossible Score

## Chapter 1: The Recruiting Drive

[Scene 1 prose...]

[Scene 2 prose...]

## Chapter 2: First Contact

[...]
```

## ğŸ› ï¸ Extending the Pipeline

### Add Custom Agents

```python
from agents.base_agent import BaseAgent

class MyCustomAgent(BaseAgent):
    def get_prompt(self):
        return "Your custom prompt here..."

    def process(self, input_data: FictionProject):
        # Your logic here
        return input_data
```

### Custom Prompts

Edit prompt templates in `utils/prompts.py` or override in agent classes.

### Add New Stages

```python
# In pipeline.py
stages = ["series", "book", "chapter", "scene", "beat", "my_custom_stage", "prose", "editorial"]
```

## ğŸ› Troubleshooting

### Common Issues

**Error: `No module named 'langchain_openai'`**
```bash
pip install langchain-openai
```

**Error: API Key not found**
```bash
# Check environment variable
echo %OPENROUTER_API_KEY%  # Windows
echo $OPENROUTER_API_KEY   # Linux/Mac

# Or pass directly:
pipeline = FictionPipeline(openrouter_api_key="your-key")
```

**Error: JSON parsing failed**
- Agent returned invalid JSON
- Check logs in `logs/` directory
- Try lowering temperature or using more capable model

**Error: Rate limit exceeded**
- Add delays between API calls
- Switch to different model
- Implement exponential backoff

### Lore Breaks

If Lore Master repeatedly fails:
1. Check `editorial_reports` in output JSON
2. Review conflicting lore entries
3. Manually edit lore in `series.lore` section
4. Resume pipeline

## ğŸ“š Examples

### Minimal Series Concept

```python
concept = """
Echoes of Tomorrow
A time traveler discovers they're trapped in a loop, reliving the same day where Earth is destroyed.
science fiction thriller
"""
```

### Fantasy Series

```python
concept = """
The Shattered Crown
In a world where magic is dying, a young mage must find the fragments of an ancient artifact to save their kingdom.
epic fantasy
"""
```

### Mystery Series

```python
concept = """
The Cryptographer's Code
A librarian discovers century-old encrypted messages in books that predict modern murders.
mystery thriller
"""
```

## ğŸ¯ Roadmap

### Current Status
- âœ… Complete data schema
- âœ… Agent architecture
- âœ… Quality gates
- âœ… Series Refiner agent (full implementation)
- âš ï¸ Other agents (placeholder - expand as needed)
- âš ï¸ Lore vector store (integration ready, needs Pinecone key)
- âš ï¸ Editorial pipeline (structure in place, agents need expansion)

### Future Enhancements
- [ ] Parallel scene processing (speed optimization)
- [ ] Multi-POV character management
- [ ] Subplot tracking and weaving
- [ ] Chapter summaries for continuity
- [ ] Character consistency analyzer
- [ ] Plot hole detection (automated)
- [ ] Export to EPUB/DOCX formats
- [ ] Web UI for project management
- [ ] Collaborative editing support

## ğŸ“– Documentation

### Key Concepts

**Agents**: Specialized AI workers that handle one transformation step (e.g., outline â†’ chapters)

**Quality Gates**: Validation checkpoints that enforce quality standards before progression

**Lore**: World-building database (characters, locations, rules) enforced across all content

**Beats**: Smallest narrative units (~200-800 words each) that become prose paragraphs

**Editorial Phase**: Post-prose workflow that fixes plot holes, consistency issues, and polishes prose

### Best Practices

1. **Start small**: Generate 1 book with 10 chapters before scaling to full series
2. **Review checkpoints**: Examine JSON output after each major stage
3. **Iterate on lore**: Refine lore entries manually for better consistency
4. **Use version control**: Track your `output/` directory with git
5. **Save intermediate states**: Keep all checkpoint JSONs for rollback capability

## ğŸ¤ Contributing

This is a modular system designed for expansion. To add new agents:

1. Create new agent file in `agents/`
2. Inherit from `BaseAgent`
3. Implement `get_prompt()` and `process()` methods
4. Add to pipeline stages in `pipeline.py`
5. Update schema if needed

## ğŸ“„ License

MIT License - Use freely for commercial or personal projects.

## ğŸ™ Credits

- **Architecture**: Based on professional fiction editing workflows
- **LangChain**: Agent orchestration framework
- **OpenRouter**: Multi-model API access
- **Pydantic**: Data validation and serialization

---

**Happy Writing! ğŸ“šâœ¨**

For questions or issues, please open a GitHub issue or check the project documentation.
