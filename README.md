# Fiction Generation Pipeline

A professional-grade AI-powered fiction writing system using LangChain and OpenRouter. This implements a hierarchical agent-based workflow with quality gates, lore management, and editorial review to generate complete novels from concept to polished manuscript.

## üéØ Features

### Core Architecture
- **Agent-Based Pipeline**: Specialized AI agents for each stage of fiction creation
- **Quality Gates**: QA Agent + Lore Master validate every stage before progression
- **Lore Management**: Pinecone vector database tracks and enforces world-building consistency
- **Editorial Pipeline**: Professional editing workflow (Story Analysis ‚Üí Consistency ‚Üí Developmental ‚Üí Line Editing)
- **State Persistence**: Checkpoint and resume capability at any stage
- **Structured Data**: Complete Pydantic schemas ensure type safety and validation

### Workflow Stages

```
Series Concept
    ‚Üì
[Series Refiner] ‚Üí Creates series outline, initial lore
    ‚Üì [QA + Lore Master validation]
[Book Outliner] ‚Üí 3-act structure, character arcs, chapter scaffold
    ‚Üì [QA + Lore Master validation]
[Chapter Developer] ‚Üí Detailed chapter breakdowns with scenes
    ‚Üì [QA + Lore Master validation]
[Scene Developer] ‚Üí Scene-level detail (POV, conflicts, turning points)
    ‚Üì [QA + Lore Master validation]
[Beat Developer] ‚Üí Story beats (action, dialogue, description units)
    ‚Üì [QA + Lore Master validation]
[Prose Generator] ‚Üí Actual narrative prose from beats
    ‚Üì [QA + Lore Master validation]
[Editorial Phase] ‚Üí Story Analyst ‚Üí Consistency Validator ‚Üí Dev Editor ‚Üí Line Editor
    ‚Üì [Final QA]
[Export] ‚Üí manuscript.md + complete project.json
```

## üìÅ Project Structure

```
fiction-pipeline/
‚îú‚îÄ‚îÄ agents/                     # AI agents for each workflow stage
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ base_agent.py          # Abstract base class
‚îÇ   ‚îú‚îÄ‚îÄ series_refiner.py      # Series outline creation
‚îÇ   ‚îú‚îÄ‚îÄ book_outliner.py       # Book structure development
‚îÇ   ‚îú‚îÄ‚îÄ chapter_developer.py   # Chapter breakdown
‚îÇ   ‚îú‚îÄ‚îÄ scene_developer.py     # Scene development
‚îÇ   ‚îú‚îÄ‚îÄ beat_developer.py      # Beat creation
‚îÇ   ‚îú‚îÄ‚îÄ prose_generator.py     # Prose writing
‚îÇ   ‚îú‚îÄ‚îÄ qa_agent.py            # Quality assurance
‚îÇ   ‚îú‚îÄ‚îÄ lore_master.py         # Lore consistency checking
‚îÇ   ‚îú‚îÄ‚îÄ story_analyst.py       # Developmental story analysis
‚îÇ   ‚îú‚îÄ‚îÄ consistency_validator.py  # Continuity validation
‚îÇ   ‚îú‚îÄ‚îÄ developmental_editor.py   # Structural editing
‚îÇ   ‚îî‚îÄ‚îÄ line_editor.py         # Prose polishing
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ schema.py              # Pydantic data models
‚îú‚îÄ‚îÄ validators/
‚îÇ   ‚îî‚îÄ‚îÄ schema_validator.py    # Schema validation
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ logger.py              # Logging utilities
‚îÇ   ‚îú‚îÄ‚îÄ state_manager.py       # Checkpoint management
‚îÇ   ‚îú‚îÄ‚îÄ prompts.py             # Versioned prompt templates
‚îÇ   ‚îî‚îÄ‚îÄ lore_store.py          # Pinecone vector store wrapper
‚îú‚îÄ‚îÄ tests/                     # Unit and integration tests
‚îú‚îÄ‚îÄ output/                    # Generated JSON checkpoints
‚îú‚îÄ‚îÄ logs/                      # Execution logs
‚îú‚îÄ‚îÄ pipeline.py                # Main orchestrator
‚îú‚îÄ‚îÄ run.py                     # CLI entry point
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

## üöÄ Installation

### Prerequisites
- Python 3.10+
- OpenRouter API key ([Get one here](https://openrouter.ai/keys))
- Pinecone API key (optional, for lore management) ([Get one here](https://www.pinecone.io/))

### Setup

```bash
# Clone or download the project
cd fiction-pipeline

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
# Create .env file:
echo "OPENROUTER_API_KEY=your-key-here" > .env
echo "PINECONE_API_KEY=your-key-here" >> .env  # Optional
```

## üìù Usage

### Quick Start

```python
from pipeline import FictionPipeline
from models.schema import FictionProject, Metadata, Series, Lore
from datetime import datetime

# Create initial project
project = FictionProject(
    metadata=Metadata(
        last_updated=datetime.now(),
        last_updated_by="User",
        processing_stage="series",
        status="draft",
        project_id="my_novel_001",
        iteration=1
    ),
    series=Series(
        title="The Quantum Heist",
        premise="A team of specialists must steal an impossible artifact from a time-locked vault.",
        genre="science fiction",
        target_audience="adult",
        themes=[],
        persistent_threads=[],
        lore=Lore(),
        books=[]
    )
)

# Initialize pipeline
pipeline = FictionPipeline(
    project_id="my_novel_001",
    output_dir="output"
)

# Run complete pipeline
final_project = pipeline.run(project)

# Export manuscript
pipeline.export_manuscript(final_project, "manuscripts/")
```

### CLI Usage

```bash
# Run full pipeline from series concept
python run.py --input series_concept.txt --project-id my-novel --output output/

# Resume from checkpoint
python run.py --project-id my-novel --resume

# Run specific stage only
python run.py --project-id my-novel --stage book_outliner

# Run with editorial phase
python run.py --project-id my-novel --run-editorial
```

### Input Format (series_concept.txt)

```
The Quantum Heist
A team of specialists must steal an impossible artifact from a time-locked vault.
science fiction
```

## üé® Model Configuration (**‚úÖ FULLY CUSTOMIZABLE!**)

### Per-Agent Model Customization

Each agent in the pipeline can use a different model and parameters. Configure via **presets** or **custom configuration**.

### Quick Start: Using Presets

```python
from pipeline import FictionPipeline

# Option 1: Balanced (default) - Good quality, reasonable cost
pipeline = FictionPipeline(
    project_id="my-novel",
    preset="balanced"
)

# Option 2: Creative - Maximum creativity/temperature
pipeline = FictionPipeline(
    project_id="my-novel",
    preset="creative"
)

# Option 3: Precise - Maximum consistency, low temperature
pipeline = FictionPipeline(
    project_id="my-novel",
    preset="precise"
)

# Option 4: Cost Optimized - Uses Claude Haiku for most stages
pipeline = FictionPipeline(
    project_id="my-novel",
    preset="cost_optimized"
)

# Option 5: Premium - Claude Opus for everything (best quality, highest cost)
pipeline = FictionPipeline(
    project_id="my-novel",
    preset="premium"
)
```

### Custom Configuration Per Agent

```python
custom_config = {
    "prose": {
        "model": "anthropic/claude-3-opus",  # Best model for prose
        "temperature": 0.95,                 # Maximum creativity
        "max_tokens": 3000
    },
    "qa": {
        "model": "openai/gpt-4",            # Different provider for QA
        "temperature": 0.4
    },
    "series": {
        "temperature": 0.2                   # Very structured planning
    }
    # Other agents use defaults
}

pipeline = FictionPipeline(
    project_id="my-novel",
    model_config=custom_config
)
```

### Available Configuration Options

Each agent supports:

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `model` | str | `anthropic/claude-3.5-sonnet` | Model identifier |
| `temperature` | float | varies | 0.0-1.0 (lower=consistent, higher=creative) |
| `max_tokens` | int | varies | Maximum response length |
| `top_p` | float | None | Nucleus sampling (0.0-1.0) |
| `frequency_penalty` | float | None | Reduce repetition (-2.0 to 2.0) |
| `presence_penalty` | float | None | Encourage topic diversity (-2.0 to 2.0) |

### Default Temperatures by Agent

| Agent | Default Temp | Rationale |
|-------|--------------|-----------|
| `series` | 0.3 | Structured series planning |
| `book` | 0.3 | Logical act structure |
| `chapter` | 0.4 | Balanced scene planning |
| `scene` | 0.5 | Moderate beat creativity |
| `beat` | 0.3 | Structured beat planning |
| `prose` | **0.8** | **HIGH for creative prose** ‚ú® |
| `qa` | 0.5 | Balanced critical analysis |
| `lore` | 0.4 | Consistent lore validation |

### Preset Details

**`balanced`** (default)
- Claude 3.5 Sonnet for all agents
- Temperature: 0.3-0.8 (structured ‚Üí creative)
- Best for: General use, good quality at reasonable cost

**`creative`**
- Claude 3.5 Sonnet for all agents
- Temperature: 0.5-0.95 (moderate ‚Üí maximum creativity)
- Best for: Experimental fiction, literary prose, unique styles

**`precise`**
- Claude 3.5 Sonnet for all agents
- Temperature: 0.2-0.5 (very structured)
- Best for: Series with complex lore, technical accuracy needed

**`cost_optimized`**
- Claude Haiku for structure (series, book, chapter, scene, beat, qa, lore)
- Claude 3.5 Sonnet for prose only
- Best for: Budget-conscious projects, first drafts

**`premium`**
- Claude Opus for nearly everything
- Claude 3.5 Sonnet for beat stage only
- Temperature: Higher overall for quality + creativity
- Best for: Final polished manuscripts, maximum quality

### Available Models on OpenRouter

```python
# Anthropic (Best for creative writing)
"anthropic/claude-3.5-sonnet"  # Balanced, recommended
"anthropic/claude-3-opus"      # Best quality, highest cost
"anthropic/claude-3-haiku"     # Fast and cheap

# OpenAI
"openai/gpt-4-turbo"
"openai/gpt-4o"
"openai/gpt-4o-mini"

# Google
"google/gemini-pro-1.5"
"google/gemini-flash-1.5"

# Meta
"meta-llama/llama-3.1-405b-instruct"
"meta-llama/llama-3.1-70b-instruct"

# See full list: https://openrouter.ai/models
```

### Example: Mix and Match Providers

```python
# Use Claude for prose, GPT-4 for QA, Gemini for structure
config = {
    "series": {"model": "google/gemini-pro-1.5", "temperature": 0.3},
    "book": {"model": "google/gemini-pro-1.5", "temperature": 0.3},
    "prose": {"model": "anthropic/claude-3-opus", "temperature": 0.9},
    "qa": {"model": "openai/gpt-4", "temperature": 0.4}
}

pipeline = FictionPipeline(project_id="test", model_config=config)
```

### Configuration at Runtime

When you initialize the pipeline, it prints the active configuration:

```
ü§ñ Model Configuration:
  series       ‚Üí anthropic/claude-3.5-sonnet              (temp=0.3)
  book         ‚Üí anthropic/claude-3.5-sonnet              (temp=0.3)
  chapter      ‚Üí anthropic/claude-3.5-sonnet              (temp=0.4)
  scene        ‚Üí anthropic/claude-3.5-sonnet              (temp=0.5)
  beat         ‚Üí anthropic/claude-3.5-sonnet              (temp=0.3)
  prose        ‚Üí anthropic/claude-3-opus                  (temp=0.9)
  qa           ‚Üí openai/gpt-4                             (temp=0.4)
  lore         ‚Üí anthropic/claude-3.5-sonnet              (temp=0.4)
```

See `example_custom_models.py` for complete working examples.

## üóÇÔ∏è Data Schema

### Complete Hierarchy

```
FictionProject
‚îú‚îÄ‚îÄ metadata (version, status, stage)
‚îú‚îÄ‚îÄ series
‚îÇ   ‚îú‚îÄ‚îÄ title, premise, themes, genre
‚îÇ   ‚îú‚îÄ‚îÄ lore
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ characters (name, role, traits, relationships)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ locations (name, description, significance)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ world_elements (name, type, rules)
‚îÇ   ‚îî‚îÄ‚îÄ books[]
‚îÇ       ‚îú‚îÄ‚îÄ title, premise, themes
‚îÇ       ‚îú‚îÄ‚îÄ act_structure (3 acts with key events)
‚îÇ       ‚îú‚îÄ‚îÄ character_arcs[]
‚îÇ       ‚îî‚îÄ‚îÄ chapters[]
‚îÇ           ‚îú‚îÄ‚îÄ title, purpose, act
‚îÇ           ‚îú‚îÄ‚îÄ character_focus (POV, present, arc moments)
‚îÇ           ‚îî‚îÄ‚îÄ scenes[]
‚îÇ               ‚îú‚îÄ‚îÄ purpose, scene_type, POV, setting
‚îÇ               ‚îú‚îÄ‚îÄ conflicts[], turning_points[]
‚îÇ               ‚îî‚îÄ‚îÄ beats[]
‚îÇ                   ‚îú‚îÄ‚îÄ description, emotional_tone
‚îÇ                   ‚îî‚îÄ‚îÄ prose (content, word_count)
‚îú‚îÄ‚îÄ qa_reports[] (quality assurance feedback)
‚îú‚îÄ‚îÄ editorial_reports[] (story analysis, consistency, edits)
‚îî‚îÄ‚îÄ revision_history[] (change tracking)
```

## üîç Quality Gates

Every stage includes validation:

1. **Schema Validation**: Pydantic ensures data structure integrity
2. **QA Agent Review**: Checks structure, pacing, character arcs, themes
3. **Lore Master Validation**: Enforces consistency with established lore
4. **Retry Logic**: Automatically retries with feedback (max 3 attempts)

### Approval Flow

```
[Agent Generates Content]
    ‚Üì
[Schema Validator] ‚Üí PASS/FAIL
    ‚Üì PASS
[QA Agent] ‚Üí Scores + Approval
    ‚Üì APPROVED?
    ‚îú‚îÄ NO ‚Üí Inject feedback, retry (max 3x)
    ‚îî‚îÄ YES ‚Üí Continue
        ‚Üì
[Lore Master] ‚Üí Lore Validation
    ‚Üì APPROVED?
    ‚îú‚îÄ NO ‚Üí Inject feedback, retry (max 3x)
    ‚îî‚îÄ YES ‚Üí Advance to next stage
```

## üé≠ Lore Management (**‚úÖ IMPLEMENTED!**)

### Automatic Lore Database with Pinecone

The system automatically stores and queries lore using a vector database for consistency:

**Setup (Optional but Recommended):**

1. **Get Pinecone API Key**: Sign up at [pinecone.io](https://www.pinecone.io/)
2. **Set Environment Variable**:
   ```bash
   # Windows
   set PINECONE_API_KEY=your-pinecone-key

   # Linux/Mac
   export PINECONE_API_KEY=your-pinecone-key
   ```
3. **Enable in Pipeline**:
   ```python
   pipeline = FictionPipeline(
       project_id="my-novel",
       use_lore_db=True  # Default: True
   )
   ```

**What Happens Automatically:**

1. **After Series Refiner** ‚Üí All lore (characters, locations, world elements) stored in Pinecone
2. **Before Each Generation** ‚Üí Agents query relevant lore (semantic search, top 10 matches)
3. **During Quality Gates** ‚Üí Lore Master checks for contradictions
4. **Lore Gets Injected** ‚Üí Relevant lore added to prompts automatically

**If Pinecone Not Available:**
- System falls back to JSON-only lore storage
- Prints warning: `‚ö†Ô∏è Warning: PINECONE_API_KEY not set. Lore vector store disabled.`
- Everything still works, just without semantic lore retrieval

### Lore Workflow

```
[Series Refiner] ‚Üí Creates initial lore entries
    ‚Üì
[Store in Pinecone] ‚úÖ AUTOMATIC ‚Üí Vector embeddings
    ‚Üì
[Each Agent] ‚úÖ AUTOMATIC ‚Üí Queries relevant lore (top 10) via semantic search
    ‚Üì (Lore injected into prompts)
[Generate Content] ‚Üí Uses relevant lore context
    ‚Üì
[Lore Master] ‚Üí Quality Gate:
    ‚îú‚îÄ Detects lore breaks ‚Üí FAIL, retry with feedback
    ‚îî‚îÄ Detects new lore ‚Üí Logged in qa_reports
```

### Example Lore Query

When generating Chapter 3, the system automatically:
```python
# Behind the scenes:
lore = lore_store.query_lore(
    query="Chapter 3: The protagonist confronts the antagonist",
    project_id="my-novel",
    top_k=10
)
# Returns: protagonist details, antagonist info, relevant locations, rules
# ‚Üí Injected into prompt to ensure consistency
```

## ‚úçÔ∏è Editorial Pipeline

Professional editing workflow after prose generation:

### Phase 1: Developmental Editing

```
[Story Analyst] ‚Üí Compare prose vs. original outline
    ‚Üì Identifies:
    ‚îú‚îÄ Plot holes
    ‚îú‚îÄ Character arc breaks
    ‚îú‚îÄ Pacing issues
    ‚îî‚îÄ Theme drift
    ‚Üì
[Consistency Validator] ‚Üí Check lore/continuity
    ‚Üì Identifies:
    ‚îú‚îÄ Lore violations
    ‚îú‚îÄ Timeline conflicts
    ‚îî‚îÄ Logic gaps
    ‚Üì
[Developmental Editor] ‚Üí Fix major issues
    ‚Üì (Re-analyze until approved)
```

### Phase 2: Line Editing

```
[Line Editor] ‚Üí Sentence-level polish
    ‚Üì Improves:
    ‚îú‚îÄ Tighten prose (remove fluff)
    ‚îú‚îÄ Fix awkward sentences
    ‚îú‚îÄ Enhance descriptions
    ‚îî‚îÄ Polish voice consistency
    ‚Üì
[Final QA] ‚Üí Approval gate
    ‚Üì APPROVED?
    ‚îî‚îÄ YES ‚Üí Export manuscript
```

## üí∞ Cost Estimation

Using **Claude 3.5 Sonnet** on OpenRouter:

| Stage | API Calls | Est. Cost |
|-------|-----------|-----------|
| Series Refiner | 1 | $0.10 |
| Book Outliner | 1 per book | $0.20 |
| Chapter Developer | ~20 | $2.00 |
| Scene Developer | ~60 | $4.00 |
| Beat Developer | ~200 | $6.00 |
| Prose Generator | ~200 | $15.00 |
| QA + Lore (all stages) | ~40 | $3.00 |
| Editorial Phase | ~50 | $5.00 |
| **Total (1 book, ~100k words)** | **~600** | **~$35** |

### Cost-Saving Tips

1. **Use `cost_optimized` preset**: Automatically uses Claude Haiku for structure stages
   ```python
   pipeline = FictionPipeline(project_id="my-novel", preset="cost_optimized")
   ```
   Estimated savings: ~70% reduction ($35 ‚Üí ~$10 per book)

2. **Generate fewer chapters first**: Test with 5 chapters before full book

3. **Skip editorial**: Go straight from prose to export

4. **Use model mixing**: Cheap models for structure, good model for prose only
   ```python
   config = {
       "series": {"model": "anthropic/claude-3-haiku"},
       "book": {"model": "anthropic/claude-3-haiku"},
       "chapter": {"model": "anthropic/claude-3-haiku"},
       "scene": {"model": "anthropic/claude-3-haiku"},
       "prose": {"model": "anthropic/claude-3.5-sonnet", "temperature": 0.8}
   }
   ```

## üß™ Testing

```bash
# Run unit tests
pytest tests/test_schema.py

# Run integration tests
pytest tests/test_pipeline.py

# Test with minimal fixture
python run.py --input tests/fixtures/minimal_series.txt --project-id test-001
```

## üîß Advanced Configuration

### Environment Variables

```bash
# Required
OPENROUTER_API_KEY=sk-or-v1-...

# Optional
PINECONE_API_KEY=...  # For lore vector database
```

### Pipeline Initialization Options

```python
pipeline = FictionPipeline(
    project_id="my-novel",           # Unique identifier
    output_dir="output",             # Checkpoint directory
    openrouter_api_key="sk-or-...",  # Or use env var
    use_lore_db=True,                # Enable Pinecone (default: True)
    preset="balanced",               # Preset configuration
    model_config=None                # Custom per-agent config
)
```

### Reproducibility

For deterministic outputs (useful for testing), use low temperatures:

```python
pipeline = FictionPipeline(
    project_id="test",
    preset="precise"  # All temperatures 0.2-0.5
)
```

Note: True determinism requires model provider support (some models don't support seed parameters).

## üìä Output

### Generated Files

```
output/
‚îú‚îÄ‚îÄ my-novel_state.json         # Complete project data
‚îú‚îÄ‚îÄ my-novel_v1.json            # Checkpoint after stage 1
‚îú‚îÄ‚îÄ my-novel_v2.json            # Checkpoint after stage 2
‚îî‚îÄ‚îÄ ...

manuscripts/
‚îú‚îÄ‚îÄ my-novel_manuscript.md      # Final prose (Markdown format)
‚îî‚îÄ‚îÄ my-novel_final.json         # Complete project with all metadata
```

### Manuscript Format

```markdown
# The Quantum Heist
*A team of specialists must steal an impossible artifact from a time-locked vault.*

---

# Book 1: The Impossible Score

## Chapter 1: The Recruiting Drive

[Scene 1 prose...]

[Scene 2 prose...]

## Chapter 2: First Contact

[...]
```

## üõ†Ô∏è Extending the Pipeline

### Add Custom Agents

```python
from agents.base_agent import BaseAgent

class MyCustomAgent(BaseAgent):
    def get_prompt(self):
        return "Your custom prompt here..."

    def process(self, input_data: FictionProject):
        # Your logic here
        return input_data
```

### Custom Prompts

Edit prompt templates in `utils/prompts.py` or override in agent classes.

### Add New Stages

```python
# In pipeline.py
stages = ["series", "book", "chapter", "scene", "beat", "my_custom_stage", "prose", "editorial"]
```

## üêõ Troubleshooting

### Common Issues

**Error: `No module named 'langchain_openai'`**
```bash
pip install langchain-openai
```

**Error: API Key not found**
```bash
# Check environment variable
echo %OPENROUTER_API_KEY%  # Windows
echo $OPENROUTER_API_KEY   # Linux/Mac

# Or pass directly:
pipeline = FictionPipeline(openrouter_api_key="your-key")
```

**Error: JSON parsing failed**
- Agent returned invalid JSON
- Check logs in `logs/` directory
- Try lowering temperature or using more capable model

**Error: Rate limit exceeded**
- Add delays between API calls
- Switch to different model
- Implement exponential backoff

### Lore Breaks

If Lore Master repeatedly fails:
1. Check `editorial_reports` in output JSON
2. Review conflicting lore entries
3. Manually edit lore in `series.lore` section
4. Resume pipeline

## üìö Examples

### Minimal Series Concept

```python
concept = """
Echoes of Tomorrow
A time traveler discovers they're trapped in a loop, reliving the same day where Earth is destroyed.
science fiction thriller
"""
```

### Fantasy Series

```python
concept = """
The Shattered Crown
In a world where magic is dying, a young mage must find the fragments of an ancient artifact to save their kingdom.
epic fantasy
"""
```

### Mystery Series

```python
concept = """
The Cryptographer's Code
A librarian discovers century-old encrypted messages in books that predict modern murders.
mystery thriller
"""
```

## üéØ Roadmap

### Current Status
- ‚úÖ Complete data schema
- ‚úÖ Agent architecture
- ‚úÖ Quality gates
- ‚úÖ Series Refiner agent (full implementation)
- ‚ö†Ô∏è Other agents (placeholder - expand as needed)
- ‚ö†Ô∏è Lore vector store (integration ready, needs Pinecone key)
- ‚ö†Ô∏è Editorial pipeline (structure in place, agents need expansion)

### Future Enhancements
- [ ] Parallel scene processing (speed optimization)
- [ ] Multi-POV character management
- [ ] Subplot tracking and weaving
- [ ] Chapter summaries for continuity
- [ ] Character consistency analyzer
- [ ] Plot hole detection (automated)
- [ ] Export to EPUB/DOCX formats
- [ ] Web UI for project management
- [ ] Collaborative editing support

## üìñ Documentation

### Key Concepts

**Agents**: Specialized AI workers that handle one transformation step (e.g., outline ‚Üí chapters)

**Quality Gates**: Validation checkpoints that enforce quality standards before progression

**Lore**: World-building database (characters, locations, rules) enforced across all content

**Beats**: Smallest narrative units (~200-800 words each) that become prose paragraphs

**Editorial Phase**: Post-prose workflow that fixes plot holes, consistency issues, and polishes prose

### Best Practices

1. **Start small**: Generate 1 book with 10 chapters before scaling to full series
2. **Review checkpoints**: Examine JSON output after each major stage
3. **Iterate on lore**: Refine lore entries manually for better consistency
4. **Use version control**: Track your `output/` directory with git
5. **Save intermediate states**: Keep all checkpoint JSONs for rollback capability

## ü§ù Contributing

This is a modular system designed for expansion. To add new agents:

1. Create new agent file in `agents/`
2. Inherit from `BaseAgent`
3. Implement `get_prompt()` and `process()` methods
4. Add to pipeline stages in `pipeline.py`
5. Update schema if needed

## üìÑ License

MIT License - Use freely for commercial or personal projects.

## üôè Credits

- **Architecture**: Based on professional fiction editing workflows
- **LangChain**: Agent orchestration framework
- **OpenRouter**: Multi-model API access
- **Pydantic**: Data validation and serialization

---

**Happy Writing! üìö‚ú®**

For questions or issues, please open a GitHub issue or check the project documentation.
